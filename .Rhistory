task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
data("mtcars", package = "datasets")
data = mtcars[, 1:3]
str(data)
library("mlr3")
task_mtcars = TaskRegr$new(id = "cars", backend = data, target = "mpg")
print(task_mtcars)
task_mtcars
library("mlr3viz")
install.packages('mlr3viz', dependencies = T)
library("mlr3viz")
install.packages('vctrs', dependencies = T)
library("mlr3viz")
autoplot(task_mtcars, type = "pairs")
autoplot(task_mtcars, type = "pairs")
a <- autoplot(task_mtcars, type = "pairs")
ggsave(a)
ggplot2::ggsave(a)
rlang::last_error()
library(Cairo)
install.packages('Cairo')
library(Cairo)
Cairo::Cairo(
30, #length
30, #width
file = paste("nameofplot", ".png", sep = ""),
type = "png", #tiff
bg = "transparent", #white or transparent depending on your requirement
dpi = 300,
units = "cm" #you can change to pixels etc
)
plot(a) #p is your graph object
tinytex::install_tinytex()
mlr_tasks
mlr_tasks$get('pima')
print(mlr_tasks$get('pima'))
mlr_tasks$get('pima')$data()
mlr_tasks$get('iris')$data()
class(mlr_tasks$get('iris')$data())
mlr_tasks
as.data.table(mlr_tasks)
task_mtcars$missings()
task_mtcars$missings()
task_mtcars$man
task_mtcars$man()
task_mtcars$missings()
task_iris = mlr_tasks$get("iris")
print(task_iris)
tsk('iris')
tsk('iris')
tsk('iris')$data()
task_iris$data()
task_iris$data()
tsk('iris')$data()
task_iris$data()
dim(tsk('iris')$data())
str(tsk('iris')$data())
summary(task_iris)
summary(task_iris$data())
summary(tsk('iris'))
tsk('iris')
summary(tsk('iris')$data())
reticulate::repl_python()
print('nmaku')
Y
update.packages(ask = F, checkBuilt = T)
install.packages('rlang')
install.packages("rlang")
library(discretization)
install.packages("discretization")
library(discretization)
data(iris)
mdlp(iris)$Disc.data
a <- mdlp(iris)
a$cutp
a$cutp[1]
str(iris)
a
summary(a)
a
a <- mdlp(iris)
a
str(a)
a
class(a)
a
a$Disc.data
summary(a$Disc.data)
mdlp(iris)$cutp
mdlp(iris)$cutp[1]
a <- rnorm(130, 10, 2)
mdlp(a)$cutp
dim(iris)
iris
mdlp(iris[,c(1, 5)])
mdlp(iris[,c(1, 5)])$cutp
mdlp(iris[,c(1, 5)])$cutp[1]
c(-Inf, mdlp(iris[,c(1,5)$cutp[1]]), Inf)
c(-Inf, mdlp(iris[,c(1,5])$cutp[1]]), Inf)
c(-Inf, mdlp(iris[,c(1,5])$cutp[1]), Inf)
c(-Inf, mdlp(iris[,c(1,5)])$cutp[1]), Inf)
c(-Inf, mdlp(iris[,c(1,5)])$cutp[1], Inf)
mdlp(iris[,c(1,5)])$cutp[[1]]
c(-Inf, mdlp(iris[,c(1,5)])$cutp[[1]], Inf)
iris %>% select(!c(Sepal.Length, Petal.Length))
library(tidyverse)
iris %>% select(!c(Sepal.Length, Petal.Length))
library(readxl)
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/")
pns <- NULL
for (i in 1:7) {
pns <- rbind(data, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/")
pns <- NULL
for (i in 1:7) {
pns <- rbind(data, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
list
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN NON PNS/Update Data")
non <- NULL
for (i in 1:7) {
non <- rbind(non, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN NON PNS/Update Data/", list[i])))
}
names(non)
data <- select(non, Fakultas, JK)
data
pivot_wider(data,names_from = Fakultas, values_from = n())
data <- select(non, Fakultas, JK) %>% gorup_by(Fakultas, JK) %>% summarize(n = n())
data <- select(non, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data
pivot_wider(data, names_from = Fakultas, values_from = "n")
pivot_wider(data, names_from = JK, values_from = "n")
pivot_wider(data, names_from = JK, values_from = "n")
pns <- NULL
for (i in 1:7) {
pns <- rbind(data, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/")
pns <- NULL
for (i in 1:7) {
pns <- rbind(data, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN NON PNS/Update Data")
non <- NULL
for (i in 1:7) {
non <- rbind(non, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN NON PNS/Update Data/", list[i])))
}
library(janitor)
data <- select(non, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data <- pivot_wider(data, names_from = JK, values_from = "n")
data[is.na(data)] <- 0
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
data
data <- select(pns, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data <- pivot_wider(data, names_from = JK, values_from = "n")
data[is.na(data)] <- 0
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
data
dim(pns)
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/")
pns <- NULL
for (i in 1:7) {
pns <- rbind(data, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
list
pns <- NULL
for (i in 1:7) {
pns <- rbind(pns, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
data <- select(pns, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data <- pivot_wider(data, names_from = JK, values_from = "n")
data[is.na(data)] <- 0
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
data
data1 <- select(pns, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data1 <- pivot_wider(data1, names_from = JK, values_from = "n")
data[is.na(data1)] <- 0
data1[is.na(data1)] <- 0
data1 <- adorn_totals(data1, where = c("row", "col"), name = "Total")
data1
data1 <- select(pns, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data1 <- pivot_wider(data1, names_from = JK, values_from = "n")
data1[is.na(data1)] <- 0
data1
data2 <- select(non, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data2 <- pivot_wider(data2, names_from = JK, values_from = "n")
data2[is.na(data2)] <- 0
data2
full_join(data1, data2)
left_join(data1, data2)
left_join(data1, data2, by = "Fakultas")
a <- left_join(data1, data2, by = "Fakultas")
names(a) <- c("Fak", "L", "P", "L", "P")
a
data <- left_join(data1, data2, by = "Fakultas")
data[is.na(data)] <- 0
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
data
data <- left_join(data1, data2, by = "Fakultas")
data[is.na(data)] <- 0
names(data) <- c("Fakultas", "L", "P", "L", "P")
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
data <- left_join(data1, data2, by = "Fakultas")
data[is.na(data)] <- 0
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
names(data) <- c("Fakultas", "L", "P", "L", "P", "Total")
data
library(kableExtra)
kable(data) %>%
kable_styling(bootstrap_options = "striped", full_width = F) %>%
add_header_above(c(" " = 1, "Dosen PNS" = 2, "Dosen Non PNS" = 2, " " = 1))
data2
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/")
pns <- NULL
for (i in 1:7) {
pns <- rbind(pns, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN PNS/Update/", list[i])))
}
data1 <- select(pns, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data1 <- pivot_wider(data1, names_from = JK, values_from = "n")
data1[is.na(data1)] <- 0
list <- list.files("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN NON PNS/Update Data")
non <- NULL
for (i in 1:7) {
non <- rbind(non, read_excel(paste0("G:/My Drive/# REGISTRASI DAN STATISTIK/DATA PEGAWAI/DOSEN NON PNS/Update Data/", list[i])))
}
data2 <- select(non, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data2 <- pivot_wider(data2, names_from = JK, values_from = "n")
data2[is.na(data2)] <- 0
data <- left_join(data1, data2, by = "Fakultas")
data[is.na(data)] <- 0
data <- adorn_totals(data, where = c("row", "col"), name = "Total")
names(data) <- c("Fakultas", "L", "P", "L", "P", "Total")
kable(data) %>%
kable_styling(bootstrap_options = "striped", full_width = F) %>%
add_header_above(c(" " = 1, "Dosen PNS" = 2, "Dosen Non PNS" = 2, " " = 1))
data1
data1 <- adorn_totals(data1, where = c("row"), name = "JML")
data1
data1 <- select(pns, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data1 <- pivot_wider(data1, names_from = JK, values_from = "n")
data1[is.na(data1)] <- 0
data1 <- adorn_totals(data1, where = c("col"), name = "JML")
data1
data2 <- select(non, Fakultas, JK) %>% group_by(Fakultas, JK) %>% summarize(n = n())
data2 <- pivot_wider(data2, names_from = JK, values_from = "n")
data2[is.na(data2)] <- 0
data2 <- adorn_totals(data2, where = c("col"), name = "JML")
data2
data <- left_join(data1, data2, by = "Fakultas")
data
data$Total <- data[,4] + data[,7]
data
data$Total <- data[,4] + data[,7]
data
data <- left_join(data1, data2, by = "Fakultas")
data$Total <- data$JML.x + data$JML.y
data
data <- adorn_totals(data, where = c("row"), name = "Total")
data
names(data) <- c("Fakultas", "L", "P", "JML", "L", "P", "JML", "Total")
data
kable(data) %>%
kable_styling(bootstrap_options = "striped", full_width = F) %>%
add_header_above(c(" " = 1, "Dosen PNS" = 3, "Dosen Non PNS" = 3, " " = 1))
setwd("G:/My Drive/# REGISTRASI DAN STATISTIK/Website/update_data_dosen")
